{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 · Multi-step Planning, Bottlenecks, and Beam / Pruned Search\n",
    "\n",
    "This notebook explores the computational bottleneck in multi-step active inference planning and shows how **observation pruning** and **beam search** reduce compute while often preserving action quality.\n",
    "\n",
    "**Key idea**: Evaluating depth-$H$ policies with expected free energy (EFE) branches over both actions and **counterfactual observations**, scaling roughly like $(|\\mathcal A|\\,|\\mathcal O|)^H$ on discrete toys. We profile wall-time and node expansions, and compare exact recursion vs. pruned recursion vs. beam search.\n",
    "\n",
    "We use the ring-world generative model from the library:\n",
    "- $A[o,s] = P(o\\mid s)$ (likelihood), $B[a][s',s]=P(s'\\mid s,a)$ (transition), $C$ (log-preferences).\n",
    "- Planning APIs (from `persystems.planning`):\n",
    "  - `choose_action_planner(...)` — depth-$H$ recursion with **observation-branch pruning**.\n",
    "  - `choose_action_beam(...)` — depth-$H$ **beam search** over action sequences.\n",
    "\n",
    "Outputs: nodes expanded, pruned branches, wall-time, action agreement across methods, and example EFE vectors $G(a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI-friendly params: shrink work if running in GitHub Actions\n",
    "import os, time\n",
    "CI = os.getenv(\"CI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "HORIZONS = [1, 2, 3] if CI else [1, 2, 3, 4]\n",
    "N_TRIALS_PER_H = 2 if CI else 5\n",
    "PRUNE_LEVELS = [1e-3, 1e-4] if CI else [1e-2, 1e-3, 1e-4]\n",
    "BEAM_WIDTHS = [8, 16] if CI else [8, 16, 32]\n",
    "print({\"CI\": CI, \"HORIZONS\": HORIZONS, \"N_TRIALS_PER_H\": N_TRIALS_PER_H})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: ring-world GM and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from persystems.gm import GenerativeModel\n",
    "from persystems.planning import choose_action_planner, choose_action_beam\n",
    "\n", 
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "def make_world(N=5, A_eps=0.15, target=3, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    gm = GenerativeModel.make_ring_world(N=N, A_eps=A_eps, target_idx=target)\n",
    "    qs0 = np.ones(N)/N\n",
    "    return gm, qs0, rng\n",
    "\n",
    "gm, qs0, rng = make_world()\n",
    "N = gm.A.shape[0]\n",
    "print(\"Actions:\", gm.actions, \"| N states:\", N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark functions\n",
    "We benchmark wall-time and node counts for:\n",
    "\n",
    "- **Exact recursion with pruning** (`choose_action_planner`): set `obs_prune_eps` → 0 for exact enumeration.\n",
    "- **Beam search** (`choose_action_beam`): set `beam_width` and (optionally) a small observation prune threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_planner(gm, qs, H, prune_eps):\n",
    "    t0 = time.perf_counter()\n",
    "    a_idx, comp, Gs, diags = choose_action_planner(qs, gm.A, gm.B, gm.C, horizon=H, obs_prune_eps=prune_eps)\n",
    "    dt = time.perf_counter() - t0\n",
    "    return {\n",
    "        \"method\": f\"planner(prune={prune_eps})\", \"H\": H, \"a\": a_idx, \"dt\": dt,\n",
    "        \"nodes\": diags.nodes_expanded, \"pruned\": diags.pruned_obs, \"Gs\": Gs\n",
    "    }\n",
    "\n",
    "def bench_beam(gm, qs, H, beam_width, prune_eps):\n",
    "    t0 = time.perf_counter()\n",
    "    a_idx, comp, Gs, diags = choose_action_beam(qs, gm.A, gm.B, gm.C, horizon=H, beam_width=beam_width, obs_prune_eps=prune_eps)\n",
    "    dt = time.perf_counter() - t0\n",
    "    return {\n",
    "        \"method\": f\"beam(K={beam_width}, prune={prune_eps})\", \"H\": H, \"a\": a_idx, \"dt\": dt,\n",
    "        \"nodes\": diags.nodes_expanded, \"pruned\": diags.pruned_obs, \"Gs\": Gs, \"beam\": beam_width\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep horizon $H$ and compare exact vs. beam\n",
    "We keep the belief uniform to focus on the planning cost itself. For each $H$, we run multiple trials (identical here, but leaves room for stochastic variants) and summarize median wall-time, nodes, and action choice agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for H in HORIZONS:\n",
    "    for trial in range(N_TRIALS_PER_H):\n",
    "        # exact (no pruning)\n",
    "        rec = bench_planner(gm, qs0, H=H, prune_eps=0.0)\n",
    "        records.append(rec)\n",
    "        # pruned variants\n",
    "        for pe in PRUNE_LEVELS:\n",
    "            records.append(bench_planner(gm, qs0, H=H, prune_eps=pe))\n",
    "        # beams\n",
    "        for bw in BEAM_WIDTHS:\n",
    "            for pe in PRUNE_LEVELS:\n",
    "                records.append(bench_beam(gm, qs0, H=H, beam_width=bw, prune_eps=pe))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes expanded vs. horizon\n",
    "Exact recursion should grow rapidly with $H$, while beam/pruned methods grow more slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_nodes(df):\n",
    "    grp = df.groupby([\"method\", \"H\"]).agg(nodes_median=(\"nodes\", \"median\"), nodes_mean=(\"nodes\", \"mean\")).reset_index()\n",
    "    return grp\n",
    "\n",
    "g_nodes = summarize_nodes(df)\n",
    "plt.figure(figsize=(7,4))\n",
    "for m, sub in g_nodes.groupby(\"method\"):\n",
    "    plt.plot(sub[\"H\"], sub[\"nodes_median\"], marker='o', label=m)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('horizon H')\n",
    "plt.ylabel('nodes expanded (median, log scale)')\n",
    "plt.title('Search complexity vs. horizon')\n",
    "plt.legend(fontsize=7)\n",
    "plt.tight_layout(); plt.show()\n",
    "g_nodes.sort_values([\"H\", \"nodes_median\"]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall-time vs. horizon\n",
    "Wall-time tracks the node explosion; pruning/beam often reduce it dramatically with little effect on the chosen action in small problems like this ring world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_time = df.groupby([\"method\", \"H\"]).agg(dt_med=(\"dt\", \"median\"), dt_mean=(\"dt\", \"mean\")).reset_index()\n",
    "plt.figure(figsize=(7,4))\n",
    "for m, sub in g_time.groupby(\"method\"):\n",
    "    plt.plot(sub[\"H\"], sub[\"dt_med\"], marker='o', label=m)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('horizon H')\n",
    "plt.ylabel('wall-time (seconds, median, log scale)')\n",
    "plt.title('Compute cost vs. horizon')\n",
    "plt.legend(fontsize=7)\n",
    "plt.tight_layout(); plt.show()\n",
    "g_time.sort_values([\"H\", \"dt_med\"]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action agreement across methods\n",
    "We compare each method’s chosen action to the exact depth-$H$ action (no pruning) at the same $H$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build reference exact actions per H\n",
    "ref = df[df[\"method\"]==\"planner(prune=0.0)\"][[\"H\",\"a\"]].drop_duplicates()\n",
    "ref = ref.rename(columns={\"a\":\"a_exact\"})\n",
    "dfj = df.merge(ref, on=\"H\", how=\"left\")\n",
    "dfj[\"agree\"] = (dfj[\"a\"] == dfj[\"a_exact\"])  # bool\n",
    "\n",
    "agree_tbl = dfj.groupby([\"method\",\"H\"]).agg(\n",
    "    agree_rate=(\"agree\",\"mean\"),\n",
    "    n=(\"agree\",\"size\")\n",
    ").reset_index()\n",
    "agree_tbl.sort_values([\"H\",\"agree_rate\"], ascending=[True, False]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "for m, sub in agree_tbl.groupby(\"method\"):\n",
    "    plt.plot(sub[\"H\"], 100*sub[\"agree_rate\"], marker='o', label=m)\n",
    "plt.ylim(0, 105)\n",
    "plt.xlabel('horizon H')\n",
    "plt.ylabel('action agreement with exact (%)')\n",
    "plt.title('Quality vs. compute: agreement with exact planner')\n",
    "plt.legend(fontsize=7)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example EFE vectors $G(a)$ at depth $H=2$\n",
    "A small peek at the per-action EFE from different planners (numbers vary slightly with prune/beam heuristics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example_vectors(H=2):\n",
    "    rows = []\n",
    "    exact = bench_planner(gm, qs0, H=H, prune_eps=0.0)\n",
    "    rows.append((\"exact\", exact[\"a\"], exact[\"Gs\"]))\n",
    "    pruned = bench_planner(gm, qs0, H=H, prune_eps=1e-4)\n",
    "    rows.append((\"pruned(1e-4)\", pruned[\"a\"], pruned[\"Gs\"]))\n",
    "    beam16 = bench_beam(gm, qs0, H=H, beam_width=16, prune_eps=1e-4)\n",
    "    rows.append((\"beam(K=16,1e-4)\", beam16[\"a\"], beam16[\"Gs\"]))\n",
    "    for name, a, Gs in rows:\n",
    "        print(f\"{name:>16s} : best a={a}, Gs={np.round(Gs, 5)}\")\n",
    "\n",
    "show_example_vectors(H=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- Exact depth-$H$ planning has *exponential* observation branching; nodes and wall-time explode with $H$.\n",
    "- **Observation pruning** (drop negligible $Q(o)$) and **beam search** (keep top-$K$ partial plans) cut compute by orders of magnitude.\n",
    "- On this small ring world, pruned/beam methods often pick the *same* action as exact depth-$H$ while using far fewer nodes.\n",
    "- For larger problems, these approximations (plus amortized policies) become essential for tractable active inference planning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

