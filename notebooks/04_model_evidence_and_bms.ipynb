{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 · Model Evidence & Bayesian Model Selection (FFX & RFX)\n",
    "\n",
    "This notebook demonstrates how to compute **marginal log-evidence** for discrete generative models and use it for **Bayesian model selection**:\n",
    "\n",
    "- **Fixed-effects (FFX):** assumes a single model generated all sequences; compares summed log-evidence.\n",
    "- **Random-effects (RFX):** assumes sequences may come from *different* models; infers model frequencies with a Dirichlet posterior and computes **exceedance probabilities**.\n",
    "\n",
    "We construct two similar models differing only in their observation noise (likelihood $A$) and generate synthetic data from the lower-noise model. We then check that BMS prefers the true model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI-friendly params\n",
    "import os\n",
    "CI = os.getenv(\"CI\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "N_SEQ      = 4   if CI else 16   # number of sequences (subjects/episodes)\n",
    "T_PER_SEQ  = 30  if CI else 60   # length per sequence\n",
    "NSAMPLES_RFX = 2000 if CI else 20000  # Dirichlet sampling for exceedance\n",
    "print({\"CI\": CI, \"N_SEQ\": N_SEQ, \"T_PER_SEQ\": T_PER_SEQ, \"NSAMPLES_RFX\": NSAMPLES_RFX})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from persystems.gm import GenerativeModel\n",
    "from persystems.bms import log_evidence_discrete, compare_models_ffx, compare_models_rfx\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build two close models and generate data from model 0\n",
    "We create two ring-world models that differ in the likelihood noise parameter $A_\\varepsilon$; lower noise (0.10) should better explain data generated under it than higher noise (0.30). Actions are chosen randomly to avoid policy confounds; you could also plug in an active-inference policy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "gm0 = GenerativeModel.make_ring_world(N=N, A_eps=0.10, target_idx=3)  # true generator\n",
    "gm1 = GenerativeModel.make_ring_world(N=N, A_eps=0.30, target_idx=3)\n",
    "models = [\n",
    "    {\"A\": gm0.A, \"B\": gm0.B, \"name\": \"Aeps=0.10\"},\n",
    "    {\"A\": gm1.A, \"B\": gm1.B, \"name\": \"Aeps=0.30\"},\n",
    "]\n",
    "\n",
    "def gen_sequence(gm, T, rng):\n",
    "    true_s = rng.integers(0, N)\n",
    "    acts, obs = [], []\n",
    "    for t in range(T):\n",
    "        a_idx = rng.integers(0, len(gm.B))                 # random actions for data gen\n",
    "        true_s = (true_s + gm.actions[a_idx]) % N\n",
    "        o = int(rng.choice(np.arange(N), p=gm.A[:, true_s]))\n",
    "        acts.append(a_idx); obs.append(o)\n",
    "    return acts, obs\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "sequences = [gen_sequence(gm0, T_PER_SEQ, rng) for _ in range(N_SEQ)]\n",
    "len(sequences), len(sequences[0][0]), len(sequences[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute marginal log-evidence per model (FFX view)\n",
    "We compute exact marginal log-evidence by forward filtering (summing predictive likelihoods $Q(o_t)$ along each sequence). Under FFX, we sum log-evidence over all sequences and compare posteriors across models via a softmax with (optional) log-priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-sequence, per-model log evidence\n",
    "LE = np.zeros((N_SEQ, len(models)))\n",
    "for s_idx, (acts, obs) in enumerate(sequences):\n",
    "    for m_idx, m in enumerate(models):\n",
    "        LE[s_idx, m_idx] = log_evidence_discrete(m[\"A\"], m[\"B\"], acts, obs)\n",
    "\n",
    "LE_df = pd.DataFrame(LE, columns=[m[\"name\"] for m in models])\n",
    "LE_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFX: summed evidence and posterior over models\n",
    "We expect the lower-noise model (Aeps=0.10) to dominate when it generated the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffx = compare_models_ffx(models, sequences)\n",
    "totals = ffx[\"log_evidence\"]\n",
    "post   = ffx[\"post\"]\n",
    "ffx_table = pd.DataFrame({\"model\": [m[\"name\"] for m in models],\n",
    "                          \"sum_log_evidence\": totals,\n",
    "                          \"posterior\": post})\n",
    "ffx_table.sort_values(\"sum_log_evidence\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "x = np.arange(len(models))\n",
    "plt.bar(x-0.2, totals - totals.max(), width=0.4, label='Δ log evidence (vs max)')\n",
    "plt.bar(x+0.2, post, width=0.4, label='posterior (FFX)')\n",
    "plt.xticks(x, [m['name'] for m in models])\n",
    "plt.title('Fixed-effects BMS: evidence & posterior')\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFX: model frequencies and exceedance probabilities\n",
    "Under random-effects BMS, each sequence may come from a different model; we infer a Dirichlet posterior over model frequencies and estimate **exceedance probabilities** via Monte Carlo sampling from the Dirichlet posterior.\n",
    "\n",
    "We again expect the true model (Aeps=0.10) to have the largest exceedance probability if it explains most sequences better than the alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfx = compare_models_rfx(models, sequences, alpha0=1.0, nsamples=NSAMPLES_RFX)\n",
    "alpha = rfx[\"alpha\"]\n",
    "ex    = rfx[\"exceedance\"]\n",
    "rmean = rfx[\"r_mean\"]\n",
    "rfx_table = pd.DataFrame({\"model\": [m[\"name\"] for m in models],\n",
    "                          \"alpha\": alpha,\n",
    "                          \"mean_freq\": rmean,\n",
    "                          \"exceedance_prob\": ex})\n",
    "rfx_table.sort_values(\"exceedance_prob\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9,4))\n",
    "x = np.arange(len(models))\n",
    "ax[0].bar(x, rmean)\n",
    "ax[0].set_xticks(x); ax[0].set_xticklabels([m['name'] for m in models])\n",
    "ax[0].set_title('RFX: posterior mean frequencies')\n",
    "ax[0].set_ylim(0,1)\n",
    "ax[1].bar(x, ex)\n",
    "ax[1].set_xticks(x); ax[1].set_xticklabels([m['name'] for m in models])\n",
    "ax[1].set_title('RFX: exceedance probabilities')\n",
    "ax[1].set_ylim(0,1)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity: per-sequence responsibilities (which model explains which sequence?)\n",
    "RFX internally computes soft responsibilities per sequence (posterior over models for that sequence). This is useful to diagnose **mixtures** (e.g., when some sequences truly came from different models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = rfx[\"responsibilities\"]  # shape (S, M)\n",
    "resp_df = pd.DataFrame(resp, columns=[m[\"name\"] for m in models])\n",
    "resp_df.index.name = 'sequence'\n",
    "resp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- **Log-evidence** is the principled score for comparing generative models; FEP/ELBO connects variational free energy to model evidence.\n",
    "- **FFX** pools evidence across sequences; **RFX** infers model *frequencies* and is robust to heterogeneity.\n",
    "- On synthetic data generated by the low-noise model, both FFX and RFX (typically) favor **Aeps=0.10** with higher evidence/posterior/exceedance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

